---
title: "SIM. Assignment 2: Telco Customer Churn"
author: "Adrià Casanova, Víctor Garcia, Zhengyong Ji"
date: "2024-01-05"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: no
editor_options:
  chunk_output_type: console
---

- Residual analysis at the end of the project.
- Profiling: AN EXTRA POINT TO BE DONE. WE CAN DO IT LATTER. USE THE SCRIPT PROVIDED BY MVA.



In this project, we will study the data set "Telco Customer Churn", which can be found at https://www.kaggle.com/datasets/blastchar/telco-customer-churn. Our goal is to analyze the correlation between the amount of customers who left within the last month (Churn) and different features that describe the customer and the services he/she/they has signed up for. Then, we will build a logistic model that will allow us to predict the variable Churn.

All members have contributed equally to all parts of the project.

```{r Clean workspace. Load libraries, echo=F, message=FALSE, warning=FALSE, results='hide'}
if(!is.null(dev.list())) dev.off()
rm(list = ls())

library(dplyr) 
library(car)
library(DataExplorer)
library(FactoMineR)
library(caTools)
library(chemometrics)
library(corrplot)
source("profiling_func.R")
library(ROSE)
```

We start importing the dataset.

```{r Import dataset}
df = read.csv("WA_Fn-UseC_-Telco-Customer-Churn.xls",header=T, sep=",",
              stringsAsFactors=TRUE)
str(df)
summary(df)
```

The data set contains 7043 observations of 21 variables.

# 1. Data preparation

The first part of the project consisted on doing some basic data preparation to ensure that data is ready for the next sections.

Firstly, we checked that all datatypes were consistent with the metadata and declared "SeniorCitizen" as a factor, as it represented a qualitative concept.

```{r SeniorCitizen to categorical}
df$SeniorCitizen <- factor(df$SeniorCitizen, labels = c("Yes", "No"))
```

Secondly, we discretized all numeric variables by splitting data into 4 categories. Their boundaries were obtained simply by dividing the total range in 4 equal intervals and the distribution was checked using histograms to ensure that they were similar to the original variables.

```{r Discretize tenure}
df$c.tenure <- df$tenure # Create a new variable called Categorical.tenure
m.tenure <- max(df$tenure, na.rm = TRUE)
df$c.tenure <- replace(df$c.tenure, df$tenure <= m.tenure/4, m.tenure/4)
for (i in 1:3) {
  idx <- (m.tenure*i/4 < df$tenure) & (df$tenure <= m.tenure*(i+1)/4)
  df$c.tenure <- replace(df$c.tenure, idx, m.tenure*(i+1)/4)
}
min(df$tenure, na.rm = TRUE)
breakpts <- seq(m.tenure/4, m.tenure, m.tenure/4); breakpts
df$c.tenure <- factor(df$c.tenure, labels = c("(-1,18]", "(18,36]",
                                              "(36,54]", "(54,72]"))
summary(df$c.tenure)
par(mfrow=c(1,2))
plot(df$c.tenure, main = "Barplot of df$c.tenure")
hist(df$tenure)
```

```{r Discretize TotalCharges}
df$c.TotalCharges <- df$TotalCharges
m.TotalCharges <- max(df$TotalCharges, na.rm = TRUE)
df$c.TotalCharges <- replace(df$c.TotalCharges, df$TotalCharges <= m.TotalCharges/4, m.TotalCharges/4)
for (i in 1:3) {
  idx <- (m.TotalCharges*i/4 < df$TotalCharges) & (df$TotalCharges <=
                                                     m.TotalCharges*(i+1)/4)
  df$c.TotalCharges <- replace(df$c.TotalCharges, idx, m.TotalCharges*(i+1)/4)
}
breakpts <- seq(m.TotalCharges/4, m.TotalCharges, m.TotalCharges/4); breakpts
df$c.TotalCharges <- factor(df$c.TotalCharges, labels = c("(-1,2171]",
                                                          "(2171,4342]", 
                                                          "(4342,6514]",
                                                          "(6514,8685]"))
summary(df$c.TotalCharges)
par(mfrow=c(1,2))
plot(df$c.TotalCharges, main = "Barplot of df$c.TotalCharges")
hist(df$TotalCharges)
```

```{r Discretize MonthlyCharges}
df$c.MonthlyCharges <- df$MonthlyCharges
m.MonthlyCharges <- max(df$MonthlyCharges, na.rm = TRUE)
df$c.MonthlyCharges <- replace(df$c.MonthlyCharges, df$MonthlyCharges <= m.MonthlyCharges/4, m.MonthlyCharges/4)
for (i in 1:3) {
  idx <- (m.MonthlyCharges*i/4 < df$MonthlyCharges) & (df$MonthlyCharges <=
                                                       m.MonthlyCharges*(i+1)/4)
  df$c.MonthlyCharges <- replace(df$c.MonthlyCharges, idx,
                                 m.MonthlyCharges*(i+1)/4)
}
min(df$MonthlyCharges, na.rm = TRUE)
breakpts <- seq(m.MonthlyCharges/4, m.MonthlyCharges, m.MonthlyCharges/4)
breakpts
df$c.MonthlyCharges <- factor(df$c.MonthlyCharges, labels = c("(18,30.69]",
                                                          "(30.69,59.38]", 
                                                          "(59.38,89.06]",
                                                          "(89.06,118.75]"))
summary(df$c.MonthlyCharges)
par(mfrow=c(1,2))
plot(df$c.MonthlyCharges, main = "Barplot of df$c.MonthlyCharges")
hist(df$MonthlyCharges)
par(mfrow=c(1,1))
```

Lastly, we identified categorical and numerical variables for later use.

```{r Identify categorical and numerical variables}
numeric_val_idx = which(sapply(df, is.numeric))
numeric_val = names(df)[numeric_val_idx]
# The only numerical features that we have are tenure, MonthlyCharges and TotalChages.

# So the remaining will be categorical features.
categoric_val_idx = which(sapply(df, is.factor))
categoric_val = names(df)[categoric_val_idx]
```


# 2. Exploratory Data Analysis (EDA)

EDA was done mainly automatically using the "DataExplorer" library. It plots, for each variable, the distribution of numeric variables, the proportion of individuals in each category and the amount of missing values, among other metadata.

The main conclusions of this section are:
1- Using the QQ plots and distribution plots we see that no numerical variable is normally distributed. This was also checked visually and with Kolmogorov-Smirnov tests, a more suitable approach than Shappiro-Wilk for large samples.

2- Our database is not balanced in some categories, like PhoneService (9% of "No") or SeniorCitizen(16% of "No"). This is specially relevant for the target, "Churn", that has 30% of cases of "No", so individuals that churned will be more difficult to predict.

3- Qualitative variables have a maximum of 4 levels, so all of them may be suitable for modeling without any aggregation.

5- Some categories, like "OnlineSecurity" or "OnlineBackup", are not applicable if the client does not have an internet connection. Consequently, there is a special level for those cases that contains around 30% of the clients. 

```{r EDA}
# Basic EDA
summary(df)

# Completed EDA 
#create_report(df, output_file = "Telco.html")
```

```{r Analysis of normality}
# tests
ks.test(df$TotalCharges, "pnorm")
ks.test(df$MonthlyCharges, "pnorm")
ks.test(df$tenure, "pnorm")

# plots
par(mfrow=c(1,2))
hist(df$tenure, prob = TRUE, breaks = 10, main = 'Histogram of tenure 
     vs normal distribution', xlab = 'tenure')
x <- seq(min(df$tenure), max(df$tenure), by = .1)
y <- dnorm(x, mean = mean(df$tenure), sd = sd(df$tenure))
plot(x,y, xlab = 'tenuere', ylab = '')

hist(df$TotalCharges, prob = TRUE, breaks = 10, main = 'Hist totalCharges 
     vs normal distribution', xlab = 'TotalCharges')
x <- seq(min(df$TotalCharges, na.rm = TRUE), max(df$TotalCharges, na.rm = TRUE),
         by = 10)
y <- dnorm(x, mean = mean(df$TotalCharges, na.rm = TRUE), sd = sd(df$TotalCharges, na.rm = TRUE))
plot(x,y, xlab = 'TotalCharges', ylab = '')

hist(df$MonthlyCharges, prob = TRUE, breaks = 10, main = 'Hist MonthlyCharges 
     vs normal distribution', xlab = 'df$MonthlyCharges')
x <- seq(min(df$MonthlyCharges, na.rm = TRUE), max(df$MonthlyCharges, na.rm = TRUE),
         by = .1)
y <- dnorm(x, mean = mean(df$MonthlyCharges, na.rm = TRUE), sd = sd(df$MonthlyCharges, na.rm = TRUE))
plot(x,y, xlab = 'df$MonthlyCharges', ylab = '')

par(mfrow=c(1,1))
```

# 3. Data Quality Report

In this section we analysed the missing values, outliers and errors of numeric variables to increase the quality of data before modeling.

To start with, we detected that only "TotalCharges", and hence "c.TotalCharges", has a total of 22 missing observations. However, all of them correspond to new clients who have not receive their first invoice yet, so "TotalCharges" can not have a value. In other words, they are "not applicable cases". We naturally impute this observations with 0. 

```{r Distribution of missings}
# Distribution of missings in df per variable
apply(sapply(df, is.na), 2, sum)

# Distribution of missings in df per individual
table(apply(sapply(df, is.na), 1, sum))

# Check that all missings in "TotalCharges" correspond to individuals tenure = 0
TotalCharges.na <- which(is.na(df$TotalCharges))
sum(TotalCharges.na == which(df$tenure == 0)) == length(TotalCharges.na)

# So we transform them after creating a new numeric variable with all the missings of the database
df$n.na <- apply(sapply(df, is.na), 1, sum)

df$TotalCharges[TotalCharges.na] = 0
df$c.TotalCharges[TotalCharges.na] = "(-1,2171]"
```

Secondly, we detected data inconsistencies. For categorical values, we checked the EDA automatic reports and the summaries to ensure that all qualitative variables categories were meaningful and that there was not any misspelling errors. We also checked that all values of numeric variables were positive and reasonable.

Additionally, for "TotalCharges" we ensured that all the values were correct by manually calculating the value and comparing it to the actual total charge.

```{r Compare TotalCharges to its expected values}
# Expected total charges as the product of monthly charges and tenure
expected_total_charges = df$MonthlyCharges * df$tenure

# Plot them against the actual total charges
plot(expected_total_charges, df$TotalCharges)
# There are no outliers, so TotalCharges is consistent.
```

Thirdly, we analysed univariate outliers in numeric variables using Boxplots and the typical thresholds: 1.5 * IQR(interquartile range) for mild outliers and 3 * IQR for severe outliers. As there were not any we considered that all points were suitable for our models.

```{r Boxplots}
for (var in as.numeric(numeric_val_idx)) {
  Boxplot(df[,var], ylab = names(df)[var], main = "Boxplot") 
}
```

## 3.1 In depth analysis of missing values

Next, we will compute for every group of individuals the mean of missing values. Then we will rank the groups according to the computed mean.

```{r Mean of missings for each group}
# c.TotalCharges has missings, so it doesn't make sense to compute the mean
# of missings in its categories

interesting_cat_idx <- categoric_val_idx[-c(1,20)]
k = 0
for (i in interesting_cat_idx){
  k <- k + length(levels(df[,i]))
}
groups.na <- matrix(0, k, 2)
l = 1
for (idx in interesting_cat_idx) {
  categories.na <- tapply(df$n.na, df[,idx], mean)
  for (j in seq(length(categories.na))) {
    groups.na[l + j - 1,] <- c(categories.na[j],
                               paste(names(df)[idx], levels(df[,idx])[j],
                                     sep = "."))
  }
  l <- l + j
}
groups.na.df <- data.frame(na.perc = groups.na[,1], group = groups.na[,2])
groups.na.df[order(groups.na.df$na.perc, decreasing = TRUE),]
```

The groups with the highest proportion of missing data are made of those individuals who:

- Have a two-year contract
- Have dependents
- Pay with a mailed check

Since the set of individuals with missing data is exactly that of the new clients, we conclude that recently incorporated clients tend to: sign a two-year contract, have dependents and pay with a mailed check.

We can compute as well the pearson correlation coefficient between "n.na" and the numerical variables.

```{r n.na correlations}
# Creation of the correlation matrix
corr_mat <- cor(df[,c(numeric_val_idx, 25)],)
corr_mat

corrplot(corr_mat, order = 'hclust')
```

n.na is independent to the rest of numerical variables, probably because it evaluates to 0 in most observations.

```{r Remove n.na, echo=F, message=FALSE, warning=FALSE, results='hide'}
# We remove n.na so that it does not interfere with the rest of the project
df$n.na <- NULL
```

## 3.2 Multivariate outliers

In this section we focused on detecting the multivariate outliers using "Moutlier". We discovered 344 multivariate outliers, about 5% of the individuals, as it was expected. We decided to maintain them and only remove them in the modeling step if they turned out to be influential points.

```{r Moutlier}
set.seed(123)
res.mout <- Moutlier(df[,numeric_val_idx], quantile = 0.95, plot= FALSE)

# Visual representation
par(mfrow=c(1,2))
plot(res.mout$md, col="lightblue", pch = 19, main = 'Detection of multivariable 
outliers', xlab= 'Observation', 
     ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)

plot(res.mout$rd, col="lightblue", pch = 19, xlab= 'Observation', 
     ylab ='Robust Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))

# Identification of the outliers
outliers = which(res.mout$md>res.mout$cutoff & res.mout$rd > res.mout$cutoff) 
length(outliers)
length(outliers)/dim(df)[1]*100
```

# 5. Profiling and feature selection

## Numeric variables
We analysed the pearson correlation coefficient to detect variables that were highly related and not include them in the model. In the correlation plot of section 3.1 we see that "TotalCharges" is highly correlated with "MonthlyCharges" and "tenure" as the first one is calculated as the product of the others.

## Categorical variables
Later on, we profiled the target Churn using "gtable". This method checks whether there are significant differences between the levels of each categorical variable and the target. We get both plots and the Pearson's Chi-squared test's results. 

```{r, results='hide'}
# Analysis of all variables except the ID
profiling(df[-1], df$Churn, "Churn")
```

For each variable, the most relevant conclusions are:
- Some variables are not significant, like Gender (p=0.4866) or Phone service (p=0.3388). Consequently, if a costumer is going to churn is independent of the gender and whether he has a phone service or not

- There are variables like "MultipleLines" that even if are significant (p=0.003464) the difference among levels is small as we can see in the plots

```{r, echo=FLASE}
profiling(df[8], df$Churn, "Churn")
```

- The rest of variables, including discretized variables, have an small p value (< 2.2e-16) and there is at least one level that has big differences of the proportions with the target. For example, people that do not have an online backup churned 40% while having the backup reduce the number to 21%.

```{r, echo=FLASE}
profiling(df[11], df$Churn, "Churn")
```

## Feature Selection
Finally, we decided which variables were suitable to be included in the model. 

The id was removed, since it will not give us any knowledge nor be useful to predict the target. 

```{r Remove customerID}
df$customerID <- NULL
```

We then computed the relationship between all variables and the target:

For categorical variables all p-values are very low, less than 0.001, but the 6 variables with the lowest value are Contract, OnlineSecurity, TechSupport, c.tenure, InternetService, PaymentMethod. Note that the list includes a discretized numerical variable.

```{r catdes categorical}
# Correlation between all variables and our qualitative target Churn.
res.cat = catdes(df, 20)

# Most important categorical variables, sorted by p value
res.cat$test.chi2
```

As for numeric variables, "tenure" has the lowest p-value, much lower than those of discrete variables. As we have already seen, there is a high correlation between "MonthlyCharges", "tenure" and "TotalCharges" so we will only include in the models "TotalCharges" or "MonthlyCharges" together with "tenure".

```{r catdes numerical}
res.cat$quanti.var
```

Lastly, we decided to make an extensive profiling for the six categorical variables that we could use in the model in order to understand them better. The main conclusions for each variable were:

- Contract: The probability of churning is decreased when the contract term increases. For example, if a costumer has a month contract and changes it to an annual the probability of not churning increases from 0.58 to 0.89.

- InternetService: People that do not have an internet service do not usually churn (7%). However, if they had a Fiber optic connection, the probability to churn increases (42%). This could be explained by the fact that users with a fast internet connection try to get the best offer for the service, but it would be necessary to make a market analysis to validate this hypothesis.

- OnlineSecurity: The probability of churning is small when the customer has online security. However, having an internet connection seems a more interesting feature than the variable as "No internet service" level has a more important change of proportions than the other levels.

-TechSupport: Having a tech support increases the probability not to churn from 60% to 84%, but having internet or not is, again, a more relevant feature.

-c.tenure: Loyalty is important as people tend to churn less when they have stayed more months in the company. For example, if people have less than 1.5 they churned 44% of times, but with more than 4.5 years they churned only 0.7%.

-PaymentMethod: The proportion of people that churned is very similar in all the types of payment except for the electronic check. In this payment, the proportion to churn increases to 45% respect the 20% of other payments. 

```{r}
# Calculate the indexes of the variables to investigate
names = c("Contract", "OnlineSecurity", "TechSupport", "c.tenure", "InternetService", "PaymentMethod")
index = NULL

for (i in 1:length(names)) {
  ind = grep(names[i], colnames(df))
  index = append(index, ind)
}
index = append(index, grep("Churn", names(df)))

# Profiling of only those variables
res.cat2 = catdes(df[,index], length(index))

res.cat2$category

# Another visualization of the profiling
#profiling(df[,index], df$Churn, "Churn")
```

# 6. Modeling 

## Data splitting
```{r}
# First, let's split the dataset into training and testing set. 
# We can consider that 70% of data will be used for training purpose.

set.seed(123)

sampling = sample.split(df$Churn, SplitRatio = 0.7)
train = subset(df, sampling == TRUE)
test = subset(df, sampling == FALSE)
```

## Modelling only with numerical variables.
```{r}
# As we mentioned, there is a strong correlation between {tenure, MonthlyCharges}
# and {TotalCharges}, as the second one is simply the product of first set.
# So we will build two model with different data set, and keep the best one.

m0.set1 = glm (Churn ~ tenure + MonthlyCharges, data = train, family = binomial)
# Checking the Anova test, both variable are significant to our model.
# Hence, we won't remove any of them.
Anova(m0.set1, test = "LR")

m0.set2 = glm (Churn ~ TotalCharges, data = train, family = binomial)

# Checking the Bayesian criterion, the set {tenure, MonthlyCharges} 
# has much lower value. Hence, we'll choose this for further analysis.
BIC(m0.set1, m0.set2)
```

```{r}
# Checking possible transformation for previous model m0.set1

m0.log = glm (Churn ~ tenure + log(MonthlyCharges), data = train, family = binomial)
m0.sqrt = glm (Churn ~ sqrt(tenure) + MonthlyCharges, data = train, family = binomial)

# We have tried several transformations for both variable (sqrt, log, exp, etc),
# but BIC shows that the best model is the one with sqrt on the tenure.
BIC (m0.set1, m0.log, m0.sqrt)
```

```{r}
# Comparing categorical variables {c.tenure}. We'll like to make an comparison 
# between different kind of tenure (numerical and discretized)
m1 = glm (Churn ~ c.tenure + MonthlyCharges, data = train, family = binomial)

BIC(m1, m0.sqrt)
# Checking the AIC and BIC parameter, we decided to keep the tenure numerical, without discretization.

# We have checked alternately by changing MonthlyCharges to discretized, but
# the AIC also get worse.
```

```{r, results= 'hide'}
# Check the influential plot
influent = influencePlot(m0.sqrt)[3]; influent

# Calculate D's threshold
D_thresh <- 2/sqrt(dim(train)[1]); D_thresh

# Cook's distance obtained from influence plot are smaller than
# threshold, hence, we won't remove any point.
```

```{r}
# Adding categorical variables {Contract}
m2 = glm (Churn ~ sqrt(tenure) + MonthlyCharges + Contract, 
          data = train, family = binomial)

# Adding {contract} indeed reduce BIC of our model.
BIC(m0.sqrt, m2)
```

```{r}
# Adding categorical variables {InternetService}
m3 = glm (Churn ~ sqrt(tenure) + MonthlyCharges + Contract + InternetService, 
          data = train, family = binomial)

# Adding {InternetService} indeed reduce BIC of our model.
BIC(m2,m3)
```

We have figured out in profiling section that {InternetService} and {OnlineSecurity, TechSupport} have some level that are strongly correlated.
In case that {Internet Service} = "No", {OnlineSecurity} and {TechSupport} 
are also None ("No intervet service").

Hence, to avoid dependency and NA's features in the model, we'll need to
decide which one to keep

```{r}
# Adding categorical variables {TechSupport} and {OnlineSecurity}
m4 = glm (Churn ~ sqrt(tenure) + MonthlyCharges + Contract + OnlineSecurity 
          + TechSupport, data = train, family = binomial)

BIC(m3, m4)

# The BIC criterion for m4 is smaller, but taking into account that
# {InternetService} is more correlated with target variable {Churn} 
# and the difference of BIC is not that significant. we decided to keep
# m3, with {InternetService}.
```

```{r}
# Adding categorical variable {PaymentMethod}
m5 = glm (Churn ~ sqrt(tenure) + MonthlyCharges + Contract + InternetService
          + PaymentMethod, data = train, family = binomial)

# Adding {PaymentMethod} indeed reduce BIC of our model.
BIC(m3, m5)
```

```{r, results= 'hide'}
# Check influential plot before removing influential observation.
influent = influencePlot(m5)[3]; influent

# Calculate D's threshold
D_thresh <- 2/sqrt(dim(train)[1]); D_thresh

# Cook's distance obtained from influence plot are smaller than
# threshold, hence, we won't remove any point.
```

```{r}
# Check all the possible interactions of model m5.
m6 = glm (Churn ~ (sqrt(tenure) + MonthlyCharges + Contract + InternetService
          + PaymentMethod)^2, data = train, family = binomial)

# Use step function to find the combination with minimun AIC. 
step(m6)
```

                                 Df Deviance    AIC
<none>                                4022.7 4068.7
- sqrt(tenure):PaymentMethod      3   4031.4 4071.4
- sqrt(tenure):Contract           2   4033.0 4075.0
- MonthlyCharges:Contract         2   4035.2 4077.2
- Contract:InternetService        4   4042.4 4080.4
- MonthlyCharges:InternetService  2   4055.1 4097.1

```{r}
# Check the interaction between sqrt(tenure):PaymentMethod and
# sqrt(tenure):Contract
m7 = glm(Churn ~ sqrt(tenure) * PaymentMethod + sqrt(tenure) * Contract +
          MonthlyCharges + InternetService + PaymentMethod, data = train, 
          family = binomial)

# Based on BIC criterion, no improvement is obtained.
BIC (m5, m7)
```

```{r}
# Check the interaction between MonthlyCharges and InternetService
m8 = glm(Churn ~ sqrt(tenure) +  Contract + MonthlyCharges * InternetService 
         + PaymentMethod, data = train, family = binomial)

# BIC improved from 4174 to 4164, but with the cost of 2 degree of freedom.
BIC(m5,m8)

# It's a trade-off between simpleness of the model and the accuracy.
summary(m8)
```

```{r}
# Check the effect of linked function
m9 = glm (Churn ~ sqrt(tenure) + MonthlyCharges + Contract + InternetService
          + PaymentMethod, data = train, family = binomial(link = "probit"))

# Based on BIC criterion, no improvement is obtained.
BIC(m5, m9)
```

```{r}
influencePlot(m9)

# Observation 269 and 4273 may be an influential point, but both of them
# are smaller than threshold.
```


```{r}
# Goodness of fit

# Residual plot

residualPlots(m5)

```

# Model prediction

```{r}
# First, we compute the probability of Churn for each observation (from test) 
# with predict function.
predictions = predict(m5, test, type = "response")

# Then, for those that have a probability higher than 0.5, we can consider
# Churn == "Yes"
probability = ifelse(predictions >= 0.5, "Yes", "No")

# Finally, compute the Confusion Matrix of predicted result.
CM = table(test$Churn, probability, dnn = c("Actual Churn", "Predicted Churn")); CM

accuracy = sum(diag(CM))/dim(test)[1]*100; accuracy

roc.curve(test$Churn, probability)
```


```{r}
library(DescTools)
PseudoR2(m5, which = "McFadden")
```


